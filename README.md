# Regression and Classification Modeling Portfolio

This repository showcases a series of machine learning projects that build core skills in **statistical modeling, iterative optimization, and predictive analytics**.  
Across the projects, models are implemented from scratch to emphasize mastery of the **mathematical and computational foundations of AI and machine learning**, including gradient-based optimization, regularization, feature selection, and probabilistic modeling.

The progression of projects reflects a transition from fundamental regression methods to advanced regularized models and multiclass classification, demonstrating both technical depth and applied problem-solving.

---

## Included Projects

### 1. Mini-Batch Gradient Descent Linear Regression
- Built a **linear regression model** trained via **mini-batch gradient descent** to predict sales from advertising spend.  
- Explored **convergence dynamics**, including **coefficient trajectories** and **cost function decay**.  

**Skills:** `Linear Regression` • `Gradient-Based Optimization` • `Vectorized Computation` • `MSE Evaluation`

---

### 2. Ridge Regression with Batch Gradient Descent
- Implemented **L2-regularized regression** to predict credit card balances from demographic and financial features.  
- Conducted **hyperparameter tuning** using **five-fold cross-validation** to balance **bias and variance**.  

**Skills:** `Ridge Regression` • `Regularization` • `Batch Gradient Descent` • `Cross-Validation` • `Hyperparameter Tuning`

---

### 3. Elastic Net Regression with Coordinate Descent
- Combined **lasso (L1)** and **ridge (L2)** penalties for **feature selection and coefficient stabilization**.  
- Performed a **grid search over (λ, α)** with **cross-validation** and visualized **coefficient paths** to study sparsity vs. stability trade-offs.  

**Skills:** `Elastic Net` • `Coordinate Descent` • `Feature Selection` • `Regularization` • `Model Selection`

---

### 4. Multinomial Logistic Regression for Ancestry Classification
- Developed a **ridge-penalized multinomial logistic regression model** to classify individuals into **five continental ancestries** using **principal component genetic features**.  
- Produced **probability-based predictions** and interpreted outputs for **admixed populations**, connecting model results to **population genetics insights**.  

**Skills:** `Multiclass Logistic Regression` • `Ridge Regularization` • `Batch Gradient Descent` • `Categorical Cross-Entropy` • `Probabilistic Modeling`

---

## Skills Highlighted

- **Mathematical Foundations:**  
  - Linear and logistic regression, regularization (L1, L2, Elastic Net)  
  - Gradient-based and coordinate descent optimization  
  - Cross-entropy and mean squared error loss functions

- **Practical Machine Learning:**  
  - Feature preprocessing (centering, scaling, standardization)  
  - Model selection with **cross-validation and hyperparameter tuning**  
  - Feature selection and coefficient path analysis

- **Applied Data Science and AI Foundations:**  
  - From **classical regression** to **probabilistic classification**  
  - Interpreting model behavior and connecting outputs to **real-world phenomena**  
  - Producing **reproducible, from-scratch implementations** that reinforce theoretical understanding

---

This repository demonstrates the ability to **bridge theory and practice** in machine learning by building, tuning, and interpreting models without reliance on high-level ML libraries.  
It serves as a **portfolio of applied AI foundations**, illustrating readiness for **data science, analytics, and model development roles**.
